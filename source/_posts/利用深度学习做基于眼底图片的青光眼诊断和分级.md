---
title: 利用深度学习做基于眼底图片的青光眼诊断和分级
date: 2018-05-10 18:07:59
id: 20180510180759
tags: 
    - 深度学习
    - Keras
    - 眼底图片
    - 青光眼
    - 模型融合
categories: 深度学习与智能医疗
copyright: true
---

> 使用多种常见深度学习模型，在眼底图片上训练诊断和分级青光眼，包括确诊青光眼（Certain Glaucoma）、疑似青光眼（Subject Glaucoma）和非青光眼（Unlikely），并用可视化观察各个网络的区别。然后使用模型融合技术构造新的融合模型。
> 本文记录该实验全部设计思路、过程数据、结果分析、学习心得和经验总结。

<!-- more -->

![img1](./计算机视觉.jpg)

# 利用深度学习做基于眼底图片的青光眼诊断和分级

## 为什么做这个题

### 眼底图片还能搞一搞

智能医疗是这两年国家重点推的方向，在眼科领域，通过影像学资料（眼底图片、OCT等）自动化诊断是一大热门课题，而深度学习的爆红极大促进了该领域发展。目前，运用深度学习做基于眼底图片的眼病（青光眼（GON）、白内障、糖网（DR）、老年黄斑变性（AMD）等）诊断吸引了医学、生物信息、计算机等各领域研究者的目光。Kaggle上也曾举办[“DR自动筛查”](https://www.kaggle.com/c/diabetic-retinopathy-detection)的比赛。

笔者之前已经陆陆续续用眼底图片做了大量的实验，包括左右眼、DR、risk factor等的分类，但是都没留下什么文档记录。

五一期间去夏威夷的ARVO大会逛了一圈，发现这块还是能搞一搞，水个paper啥的。于是想好好设计一个项目，记录所有的思考过程和实验步骤，并最终输出一篇paper，同时把代码和文档开源到博客。

![img2](./ARVO.png)

### 青光眼自动诊断的研究现状

相比于DR和AMD，GON自动诊断发展相对较慢。主要原因是样本量不足，同时大量的研究趋向于用局部特征提取（血管分割、视盘/视杯分割）而非全局特征来诊断。

最近我们团队在*ophthalmology*上publish了一篇[*Efficacy of a Deep Learning System for Detecting Glaucomatous Optic Neuropathy Based on Color Fundus Photographs*](https://www.ncbi.nlm.nih.gov/pubmed/29506863)，算是在样本量和模型性能上较以往研究有较大的提升。

该文章同时也遗留了一些问题，提出了一些future work。另外我们的样本集又有所更新。基于此，我设计了本项目。

## 实验设计思路

### 可行性分析

利用[眼底图片人工诊断青光眼](http://ghomevip.com/show.asp?id=105)是临床非常常用的方法。主要是检测杯盘比。这说明了眼底图片包含了可用于诊断的特征，所以用深度学习去做自动化是可行的，之前的大量研究也提供了佐证。

![img3](./青光眼杯盘比.jpeg)

### 实验环境

|名称|容量/版本|
|--|--|
|Nvidia |3|
|Keras||
|Jupyter||

### 实验目的

本实验主要解决以下问题：

1. 多种常见模型在眼底图片自动诊断青光眼上的表现差异
2. 多种模型诊断过程的可视化比较
3. 模型融合

### 实验流程

1. 从服务器按文件名取数 -> label匹配
2. 数据清理，剔除异常值 -> 预处理
3. 数据分集 -> 保存本地
4. 编写多fine-tune模型，编写训练函数 -> 训练
5. 结果分析 -> 可视化
6. 模型融合
7. 结果比较，分析
8. 写paper

## 实验步骤、代码、笔记
